{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6b0bc2-a7d5-4798-b60d-585a459e0ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5fb5fc-ab5c-4173-a3ba-e5d35db05a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "n_head = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efebc6ca-9559-4b3f-9b7a-17176d71ce5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.randn(16,64,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef2c0f2-a414-42e5-8288-d82355e8d617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        B, T, D = q.shape\n",
    "        \n",
    "        n_d = self.d_model // self.n_head #每个头的维度\n",
    "        \n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        \n",
    "        q = q.view(B, T, self.n_head, n_d).transpose(1,2)\n",
    "        k = k.view(B, T, self.n_head, n_d).transpose(1,2)\n",
    "        v = v.view(B, T, self.n_head, n_d).transpose(1,2)\n",
    "        \n",
    "        score = q@k.transpose(2,3) / math.sqrt(n_d)\n",
    "        \n",
    "        mask =  torch.tril(torch.ones(T, T, dtype = bool))\n",
    "        \n",
    "        score = score.masked_fill(mask == 0, -10000)\n",
    "        \n",
    "        score = self.softmax(score)\n",
    "        \n",
    "        score = score@v\n",
    "        \n",
    "        x_concate = score.transpose(1,2).contiguous().view(B,T,self.d_model)\n",
    "        x_output = self.w_o(x_concate)\n",
    "        \n",
    "        return x_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97976b43-e18d-4f64-a40b-782e4d9dc43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atte = Multi_Head_Attention(d_model, n_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44aa069-21c3-4db5-a5f8-a4ef87183f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = atte(X,X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bdac53-4494-4936-b8b0-7a9b321bfce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b18658c-de7a-4373-8c2c-b4169f281366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#层归一化 layer norm\n",
    "class Layer_Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim = True)\n",
    "        var = x.var(-1, keepdim = True)\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "834e3377-d703-4dec-97a1-10d0ff68c278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LN = Layer_Norm(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb43257-ecb4-4304-9c45-8ea5ca1b5d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model:  512\n"
     ]
    }
   ],
   "source": [
    "print(\"d_model: \", d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de36b500-e1a2-4e0c-a96c-a89eaf745377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LN gamma: torch.Size([512])\n",
      "LN beta: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(f\"LN gamma: {LN.gamma.shape}\")\n",
    "print(f\"LN beta: {LN.beta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b323fdcb-44a5-460b-bd2d-ace161f75134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "Y_ln = LN(X)\n",
    "print(Y_ln.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8daa47-5c4e-4ef3-b5e9-c52f4bef5d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
